diff --git a/kernel/mutex.c b/kernel/mutex.c
index 5449b21..9f4e742 100644
--- a/kernel/mutex.c
+++ b/kernel/mutex.c
@@ -55,7 +55,7 @@ EXPORT_SYMBOL(__mutex_init);
  * We also put the fastpath first in the kernel image, to make sure the
  * branch is predicted by the CPU as default-untaken.
  */
-static void fastcall noinline __sched
+static __used void fastcall noinline __sched
 __mutex_lock_slowpath(atomic_t *lock_count __IP_DECL__);
 
 /***
@@ -91,7 +91,7 @@ void fastcall __sched mutex_lock(struct mutex *lock)
 
 EXPORT_SYMBOL(mutex_lock);
 
-static void fastcall noinline __sched
+static __used void fastcall noinline __sched
 __mutex_unlock_slowpath(atomic_t *lock_count __IP_DECL__);
 
 /***
@@ -188,7 +188,7 @@ __mutex_lock_common(struct mutex *lock, long state __IP_DECL__)
 	return 0;
 }
 
-static void fastcall noinline __sched
+static __used void fastcall noinline __sched
 __mutex_lock_slowpath(atomic_t *lock_count __IP_DECL__)
 {
 	struct mutex *lock = container_of(lock_count, struct mutex, count);
@@ -199,7 +199,7 @@ __mutex_lock_slowpath(atomic_t *lock_count __IP_DECL__)
 /*
  * Release the lock, slowpath:
  */
-static fastcall noinline void
+static __used fastcall noinline void
 __mutex_unlock_slowpath(atomic_t *lock_count __IP_DECL__)
 {
 	struct mutex *lock = container_of(lock_count, struct mutex, count);
